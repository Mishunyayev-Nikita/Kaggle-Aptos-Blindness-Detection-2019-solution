model_params:
  model: efficientnet_pretrained
  k: 4
  num_classes: 1
  pretrained: True

distributed_params:
  opt_level: O1

args:
  expdir: "src"
  logdir: &logdir "./logs/efficientnet-4/finetuning_combined_256"

stages:

  data_params:
    batch_size: 64
    num_workers: 12
    in_csv: "./data/train.csv"
    class_column: "diagnosis"
    input_column: "id_code"
    train_folds: [0, 1, 2, 3, 4]
    valid_folds: [4]
    datapath: "./data/train_images"
    image_size: 256
    upsampling: False
    crop_from_gray: True
    circle_crop: True
    normalize: True
    ben_preprocess: 10
    hor_flip: 0.5
    ver_flip: 0.33
    rotate: 360
    random_scale: 0.35
    random_scale_p: 0.75
    brightness: 0.35
    contrast: 0.35
    color_p: 0.5

  criterion_params:
    criterion: MSELoss
  
  stage1:
    data_params:
      batch_size: 64
    state_params:
      num_epochs: &num_epochs 5
      main_metric: &reduce_metric kappa_score
      minimize_metric: False

    optimizer_params:
      optimizer: Adam
      lr: 0.001
      weight_decay: 0.000001

    #scheduler_params:
      #scheduler: MultiStepLR
      #milestones: [2, 3]
      #gamma: 0.1
      #scheduler: OneCycleLR
      #num_steps: *num_epochs
      #lr_range: [0.0001, 0.00004]
      #init_lr: 0.0004
      #warmup_fraction: 0.3

    callbacks_params:
      loss:
        callback: CriterionCallback
      optimizer:
        callback: OptimizerCallback
      #scheduler:
      #  callback: SchedulerCallback
      #  reduce_metric: *reduce_metric
      saver:
        callback: CheckpointCallback
        #resume: "./logs/efficientnet-3/pretraining_combined_256/checkpoints/stage2.7.pth"
      kappa:
        callback: KappaCallback
        num_classes: 5
        regression: True
  stage2:
    data_params:
      batch_size: 32
    state_params:
      num_epochs: 18
      main_metric: kappa_score
      minimize_metric: False

    optimizer_params:
      optimizer: Adam
      lr: 0.0001
      weight_decay: 0.000001

    scheduler_params:
      #scheduler: MultiStepLR
      #milestones: [3, 6]
      #gamma: 0.1
      scheduler: OneCycleLR
      num_steps: *num_epochs
      lr_range: [0.001, 0.00004]
      init_lr: 0.001
      warmup_fraction: 0.3

    callbacks_params:
      loss:
        callback: CriterionCallback
      optimizer:
        callback: OptimizerCallback
      scheduler:
        callback: SchedulerCallback
        reduce_metric: *reduce_metric
      saver:
        callback: CheckpointCallback
      kappa:
        callback: KappaCallback
        num_classes: 5
        regression: True